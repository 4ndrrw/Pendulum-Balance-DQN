{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7a98812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym==0.17.3 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (0.17.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from gym==0.17.3) (1.10.1)\n",
      "Requirement already satisfied: numpy>=1.10.4 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from gym==0.17.3) (1.24.3)\n",
      "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from gym==0.17.3) (1.5.0)\n",
      "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from gym==0.17.3) (1.6.0)\n",
      "Requirement already satisfied: future in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from pyglet<=1.5.0,>=1.4.0->gym==0.17.3) (1.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ensorflow (c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow (c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow (c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (3.7.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from matplotlib) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from matplotlib) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: numpy<2,>=1.20 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from matplotlib) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from matplotlib) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from matplotlib) (6.4.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib) (3.20.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ensorflow (c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow (c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow (c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==2.10\n",
      "  Using cached tensorflow-2.10.0-cp38-cp38-win_amd64.whl.metadata (3.1 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from tensorflow==2.10) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from tensorflow==2.10) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from tensorflow==2.10) (25.2.10)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from tensorflow==2.10) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from tensorflow==2.10) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from tensorflow==2.10) (3.11.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from tensorflow==2.10) (1.1.2)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from tensorflow==2.10) (18.1.1)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from tensorflow==2.10) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from tensorflow==2.10) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from tensorflow==2.10) (24.1)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from tensorflow==2.10) (3.19.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from tensorflow==2.10) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from tensorflow==2.10) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from tensorflow==2.10) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from tensorflow==2.10) (4.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from tensorflow==2.10) (1.17.2)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from tensorflow==2.10) (0.31.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from tensorflow==2.10) (1.70.0)\n",
      "Requirement already satisfied: tensorboard<2.11,>=2.10 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from tensorflow==2.10) (2.10.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from tensorflow==2.10) (2.10.0)\n",
      "Requirement already satisfied: keras<2.11,>=2.10.0 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from tensorflow==2.10) (2.10.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from astunparse>=1.6.0->tensorflow==2.10) (0.44.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10) (2.40.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10) (3.7)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10) (2.32.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10) (3.0.6)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10) (4.9.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow==2.10) (2.0.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow==2.10) (7.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow==2.10) (2.1.3)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow==2.10) (3.20.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10) (0.6.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow==2.10) (3.3.1)\n",
      "Using cached tensorflow-2.10.0-cp38-cp38-win_amd64.whl (455.9 MB)\n",
      "Installing collected packages: tensorflow\n",
      "Successfully installed tensorflow-2.10.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ensorflow (c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow (c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install gym==0.17.3\n",
    "!pip install matplotlib\n",
    "!pip install tensorflow==2.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5db404f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import gym\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f972e433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.  0.  2.]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "NUM_ACTIONS = 3 \n",
    "action_bins = np.linspace(-2, 2, NUM_ACTIONS) \n",
    "print(action_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6372242d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#qns to ask:\n",
    "#the action bins are set to -2 to 2, so the action space is continuous, but the action space in the environment is discrete, so how do i map the action bins to the discrete action space?\n",
    "\n",
    "#the parameters like gamma, epsilon, epsilon_min, epsilon_decay, learning_rate, alpha, etc. are they all correct?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "488494d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=100000)\n",
    "        self.gamma = 0.99           # Discount factor -----------------ASK CHER\n",
    "        self.epsilon = 1.0          # Exploration rate \n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.learning_rate = 0.001\n",
    "\n",
    "        self.model = self._build_model()\n",
    "\n",
    "    def _build_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(12, input_dim=self.state_size, activation='relu'))\n",
    "        model.add(Dense(12, activation='relu'))\n",
    "        model.add(Dense(self.action_size, activation='linear'))  # Q-values for each discrete action\n",
    "        model.compile(loss='mse', optimizer=Adam(learning_rate=self.learning_rate))\n",
    "        return model\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def act(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(self.action_size)\n",
    "        act_values = self.model.predict(state[np.newaxis, :], verbose=0)\n",
    "        return np.argmax(act_values[0])\n",
    "\n",
    "    def replay(self, batch_size):\n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "    \n",
    "        states = np.zeros((batch_size, self.state_size))\n",
    "        targets = np.zeros((batch_size, self.action_size))\n",
    "    \n",
    "        for i, (state, action, reward, next_state, done) in enumerate(minibatch):\n",
    "            target = reward\n",
    "            if not done:\n",
    "                target += self.gamma * np.amax(self.model.predict(next_state[np.newaxis, :], verbose=0)[0])\n",
    "            target_f = self.model.predict(state[np.newaxis, :], verbose=0)[0]\n",
    "            target_f[action] = target\n",
    "    \n",
    "            states[i] = state\n",
    "            targets[i] = target_f\n",
    "    \n",
    "        \n",
    "        self.model.fit(states, targets, epochs=1, verbose=0)\n",
    "    \n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47747c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('Pendulum-v0')  # gym 0.17.3\n",
    "state_size = env.observation_space.shape[0]\n",
    "action_size = NUM_ACTIONS  # number of discrete actions\n",
    "\n",
    "agent = DQNAgent(state_size, action_size)\n",
    "episodes = 500\n",
    "batch_size = 64\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049a8417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: Reward = -1327.6533042903798\n",
      "Episode 2: Reward = -1009.1838351485738\n",
      "Episode 3: Reward = -1351.071907843939\n",
      "Episode 4: Reward = -1275.3337342267298\n",
      "Episode 5: Reward = -1321.2789465804112\n",
      "Episode 6: Reward = -953.5066040334468\n",
      "Episode 7: Reward = -1058.124411506806\n",
      "Episode 8: Reward = -1587.7885191900361\n",
      "Episode 9: Reward = -1552.8001788677125\n",
      "Episode 10: Reward = -1246.5251047691333\n",
      "Episode 11: Reward = -984.3597635887087\n",
      "Episode 12: Reward = -991.4713378550352\n",
      "Episode 13: Reward = -1560.4806425510924\n",
      "Episode 14: Reward = -871.4464207944507\n",
      "Episode 15: Reward = -1611.214918342844\n",
      "Episode 16: Reward = -1538.2613667237495\n",
      "Episode 17: Reward = -1271.8589840928696\n",
      "Episode 18: Reward = -918.3264043221135\n",
      "Episode 19: Reward = -1178.9412822796262\n",
      "Episode 20: Reward = -1454.0159434242594\n",
      "Episode 21: Reward = -885.6098170028346\n",
      "Episode 22: Reward = -1175.3831843741543\n",
      "Episode 23: Reward = -977.0664278144861\n",
      "Episode 24: Reward = -1379.8553455679464\n",
      "Episode 25: Reward = -1310.580928366846\n",
      "Episode 26: Reward = -844.0217657968138\n",
      "Episode 27: Reward = -1409.9054691991162\n",
      "Episode 28: Reward = -1039.7379135743013\n",
      "Episode 29: Reward = -1532.0859996391212\n",
      "Episode 30: Reward = -1058.789594876095\n",
      "Episode 31: Reward = -1656.664577667467\n",
      "Episode 32: Reward = -1179.4231600554574\n",
      "Episode 33: Reward = -1478.6336876028085\n",
      "Episode 34: Reward = -1196.2988634146948\n",
      "Episode 35: Reward = -1180.1112735823724\n",
      "Episode 36: Reward = -1691.8731725510838\n",
      "Episode 37: Reward = -999.1180237265477\n",
      "Episode 38: Reward = -1203.2102876579163\n",
      "Episode 39: Reward = -1251.4008717776926\n",
      "Episode 40: Reward = -871.1003088469396\n",
      "Episode 41: Reward = -1036.07163630442\n",
      "Episode 42: Reward = -886.2735972765333\n",
      "Episode 43: Reward = -1652.4386075428786\n",
      "Episode 44: Reward = -1324.7905071688986\n",
      "Episode 45: Reward = -979.8040343494644\n",
      "Episode 46: Reward = -1070.034034378657\n",
      "Episode 47: Reward = -1237.1811136004876\n",
      "Episode 48: Reward = -1590.5819959728638\n",
      "Episode 49: Reward = -1282.8389992440366\n",
      "Episode 50: Reward = -1570.9045858825154\n",
      "Episode 51: Reward = -1184.3673884338496\n",
      "Episode 52: Reward = -1730.346115954048\n",
      "Episode 53: Reward = -1270.3012566847005\n",
      "Episode 54: Reward = -1814.7826713691652\n",
      "Episode 55: Reward = -996.4578607585345\n",
      "Episode 56: Reward = -1424.0597648240594\n",
      "Episode 57: Reward = -1067.0037401155648\n",
      "Episode 58: Reward = -1221.6393738918393\n",
      "Episode 59: Reward = -978.9912805699092\n",
      "Episode 60: Reward = -1283.8925467408797\n",
      "Episode 61: Reward = -973.3720696797332\n",
      "Episode 62: Reward = -1313.5589602723628\n",
      "Episode 63: Reward = -1024.6023679473853\n",
      "Episode 64: Reward = -1016.8452081436506\n",
      "Episode 65: Reward = -1782.475560033316\n",
      "Episode 66: Reward = -1231.7671167304438\n",
      "Episode 67: Reward = -853.8058159830308\n",
      "Episode 68: Reward = -1603.3463614008392\n",
      "Episode 69: Reward = -1516.3553221227112\n",
      "Episode 70: Reward = -848.8406194329846\n",
      "Episode 71: Reward = -967.9160632198665\n",
      "Episode 72: Reward = -1707.3838809519807\n",
      "Episode 73: Reward = -1506.7976994205362\n",
      "Episode 74: Reward = -886.8177285245723\n",
      "Episode 75: Reward = -971.1531053972677\n",
      "Episode 76: Reward = -1524.3007394488266\n",
      "Episode 77: Reward = -1626.0302407099111\n",
      "Episode 78: Reward = -1368.5010221809473\n",
      "Episode 79: Reward = -1065.3030127604516\n",
      "Episode 80: Reward = -1297.0422658371622\n",
      "Episode 81: Reward = -1726.0040198990557\n",
      "Episode 82: Reward = -1429.5527855035823\n",
      "Episode 83: Reward = -935.5586157986087\n",
      "Episode 84: Reward = -866.9000438733021\n",
      "Episode 85: Reward = -990.3781987326817\n",
      "Episode 86: Reward = -1390.4015775893092\n",
      "Episode 87: Reward = -1401.675618086169\n",
      "Episode 88: Reward = -871.6291788919167\n",
      "Episode 89: Reward = -838.0123125626365\n",
      "Episode 90: Reward = -1197.526416859324\n",
      "Episode 91: Reward = -1220.1689807004884\n",
      "Episode 92: Reward = -1071.1419109170222\n",
      "Episode 93: Reward = -1814.821040666621\n",
      "Episode 94: Reward = -1692.3176150633408\n",
      "Episode 95: Reward = -1254.5676167338768\n",
      "Episode 96: Reward = -1436.6919051335317\n",
      "Episode 97: Reward = -1412.3733999407186\n",
      "Episode 98: Reward = -896.92247070478\n",
      "Episode 99: Reward = -1355.5112122227092\n",
      "Episode 100: Reward = -872.9131300867566\n",
      "Episode 101: Reward = -1199.2294871731285\n",
      "Episode 102: Reward = -1428.378717688561\n",
      "Episode 103: Reward = -909.0819570174358\n",
      "Episode 104: Reward = -1447.154045323752\n",
      "Episode 105: Reward = -1267.821110392894\n",
      "Episode 106: Reward = -871.3607192052448\n",
      "Episode 107: Reward = -1073.9158642551479\n",
      "Episode 108: Reward = -1202.2618871304464\n",
      "Episode 109: Reward = -1028.8239787815533\n",
      "Episode 110: Reward = -1453.9940107557538\n",
      "Episode 111: Reward = -1353.0647194666385\n",
      "Episode 112: Reward = -1506.3596877880807\n",
      "Episode 113: Reward = -1060.107003301772\n",
      "Episode 114: Reward = -1015.5158688873786\n",
      "Episode 115: Reward = -1181.8002477931104\n",
      "Episode 116: Reward = -1617.1433789655289\n",
      "Episode 117: Reward = -1249.8630127279948\n",
      "Episode 118: Reward = -978.3929331269454\n",
      "Episode 119: Reward = -1598.9536879736388\n",
      "Episode 120: Reward = -1200.6915765195506\n",
      "Episode 121: Reward = -1133.8514301248626\n",
      "Episode 122: Reward = -1640.680560946713\n",
      "Episode 123: Reward = -1621.3791602735575\n",
      "Episode 124: Reward = -965.7071237116596\n",
      "Episode 125: Reward = -1507.8766220133382\n",
      "Episode 126: Reward = -1398.5287651536655\n",
      "Episode 127: Reward = -1083.6237685216893\n",
      "Episode 128: Reward = -1274.162314101892\n",
      "Episode 129: Reward = -990.0770184420641\n",
      "Episode 130: Reward = -762.9925756964117\n",
      "Episode 131: Reward = -889.3846218646629\n",
      "Episode 132: Reward = -902.7082015692268\n",
      "Episode 133: Reward = -1287.3042392595298\n",
      "Episode 134: Reward = -1564.9772597322046\n",
      "Episode 135: Reward = -1071.6357998722754\n",
      "Episode 136: Reward = -1291.225788210074\n",
      "Episode 137: Reward = -1069.6596761276044\n",
      "Episode 138: Reward = -1274.2096089225456\n",
      "Episode 139: Reward = -1574.472391509658\n",
      "Episode 140: Reward = -1118.8300371084301\n",
      "Episode 141: Reward = -868.438677382874\n",
      "Episode 142: Reward = -825.9076926777254\n",
      "Episode 143: Reward = -937.1937931162962\n",
      "Episode 144: Reward = -1061.403169360564\n",
      "Episode 145: Reward = -972.0949404856185\n",
      "Episode 146: Reward = -1584.7345681754218\n",
      "Episode 147: Reward = -883.6442464444218\n",
      "Episode 148: Reward = -879.3457585762196\n",
      "Episode 149: Reward = -1195.875748736303\n",
      "Episode 150: Reward = -1244.8483392117566\n",
      "Episode 151: Reward = -1272.909437224523\n",
      "Episode 152: Reward = -1070.1605496259774\n",
      "Episode 153: Reward = -1197.2956807522053\n",
      "Episode 154: Reward = -857.0961525421272\n",
      "Episode 155: Reward = -1178.12829807637\n",
      "Episode 156: Reward = -1056.2454925461088\n",
      "Episode 157: Reward = -1070.394275702354\n",
      "Episode 158: Reward = -1060.0780081259168\n",
      "Episode 159: Reward = -870.2404178367875\n",
      "Episode 160: Reward = -1071.4595765763165\n",
      "Episode 161: Reward = -759.0286149433321\n",
      "Episode 162: Reward = -1652.2980372193697\n",
      "Episode 163: Reward = -1288.8547209912974\n",
      "Episode 164: Reward = -1498.0299653401826\n",
      "Episode 165: Reward = -1552.0029928863419\n",
      "Episode 166: Reward = -1670.2576038218642\n",
      "Episode 167: Reward = -1378.2437474059625\n",
      "Episode 168: Reward = -1690.115541227546\n",
      "Episode 169: Reward = -1201.1555638416794\n",
      "Episode 170: Reward = -1790.119234037965\n",
      "Episode 171: Reward = -1569.3494640686115\n",
      "Episode 172: Reward = -1720.0026057306898\n",
      "Episode 173: Reward = -1825.959472654314\n",
      "Episode 174: Reward = -1689.8064386202082\n",
      "Episode 175: Reward = -1697.6130496053042\n",
      "Episode 176: Reward = -1835.9459338938884\n",
      "Episode 177: Reward = -1035.5583954571607\n",
      "Episode 178: Reward = -1639.2603961448174\n",
      "Episode 179: Reward = -1594.882692261439\n",
      "Episode 180: Reward = -1812.4882575260526\n",
      "Episode 181: Reward = -1889.391393888541\n",
      "Episode 182: Reward = -1758.4858655980695\n",
      "Episode 183: Reward = -1566.883028353001\n",
      "Episode 184: Reward = -1637.2413811880433\n",
      "Episode 185: Reward = -1464.5355357225615\n",
      "Episode 186: Reward = -1190.91333830583\n",
      "Episode 187: Reward = -1461.844030399132\n",
      "Episode 188: Reward = -1840.7305452012408\n",
      "Episode 189: Reward = -1281.8506839837555\n",
      "Episode 190: Reward = -1763.0015904049963\n",
      "Episode 191: Reward = -1458.0590909151406\n",
      "Episode 192: Reward = -1533.3356166860326\n",
      "Episode 193: Reward = -1432.7605091406724\n",
      "Episode 194: Reward = -1842.373056330807\n",
      "Episode 195: Reward = -1178.5953096804847\n",
      "Episode 196: Reward = -1332.3495467537382\n",
      "Episode 197: Reward = -1770.8664218062365\n",
      "Episode 198: Reward = -1726.4184993003387\n",
      "Episode 199: Reward = -1708.433959449063\n",
      "Episode 200: Reward = -1697.51596394637\n",
      "Episode 201: Reward = -1557.9624580163286\n",
      "Episode 202: Reward = -1739.82463740324\n",
      "Episode 203: Reward = -1754.4460939032695\n",
      "Episode 204: Reward = -1816.149870843356\n",
      "Episode 205: Reward = -1255.7999997829452\n",
      "Episode 206: Reward = -1615.644741428625\n",
      "Episode 207: Reward = -1473.0381434319575\n",
      "Episode 208: Reward = -1498.5596732460406\n",
      "Episode 209: Reward = -1685.1853225771224\n",
      "Episode 210: Reward = -1729.2827013735503\n",
      "Episode 211: Reward = -1511.7454422576714\n",
      "Episode 212: Reward = -1735.598578462275\n",
      "Episode 213: Reward = -1701.3027165897574\n",
      "Episode 214: Reward = -1426.341493892432\n",
      "Episode 215: Reward = -1489.9470928127973\n",
      "Episode 216: Reward = -1338.8717986447948\n",
      "Episode 217: Reward = -1648.6758274889091\n",
      "Episode 218: Reward = -1647.6275010908491\n",
      "Episode 219: Reward = -1636.766414303108\n",
      "Episode 220: Reward = -1667.9886535530716\n",
      "Episode 221: Reward = -1500.357807297227\n",
      "Episode 222: Reward = -1644.48031552743\n",
      "Episode 223: Reward = -1409.3477734299543\n",
      "Episode 224: Reward = -1615.497162859934\n",
      "Episode 225: Reward = -1601.059172909484\n",
      "Episode 226: Reward = -1565.0407367153318\n",
      "Episode 227: Reward = -1699.0449611408858\n",
      "Episode 228: Reward = -1769.5245708083896\n",
      "Episode 229: Reward = -1678.847535934017\n",
      "Episode 230: Reward = -1541.002012283553\n",
      "Episode 231: Reward = -1738.4508141726699\n",
      "Episode 232: Reward = -1746.3694120668563\n",
      "Episode 233: Reward = -1740.561218237546\n",
      "Episode 234: Reward = -1592.7644045568068\n",
      "Episode 235: Reward = -1868.1861603171035\n",
      "Episode 236: Reward = -1605.3977946754985\n",
      "Episode 237: Reward = -1521.200024373867\n",
      "Episode 238: Reward = -1829.8328831775775\n",
      "Episode 239: Reward = -1746.094489625336\n",
      "Episode 240: Reward = -1671.8542791540497\n",
      "Episode 241: Reward = -1488.7462277330676\n",
      "Episode 242: Reward = -1672.5267790212615\n",
      "Episode 243: Reward = -1827.3750877911505\n",
      "Episode 244: Reward = -1859.7385257485553\n",
      "Episode 245: Reward = -1801.9999747511667\n",
      "Episode 246: Reward = -1667.2138549454503\n",
      "Episode 247: Reward = -1686.986569871953\n",
      "Episode 248: Reward = -1595.366965268931\n",
      "Episode 249: Reward = -1795.926736626534\n",
      "Episode 250: Reward = -1422.7029755160372\n",
      "Episode 251: Reward = -1693.600012807044\n",
      "Episode 252: Reward = -1624.4886954959168\n",
      "Episode 253: Reward = -1803.6268561203137\n",
      "Episode 254: Reward = -1836.2050101053708\n",
      "Episode 255: Reward = -1757.2109624481698\n",
      "Episode 256: Reward = -1688.9038535457908\n",
      "Episode 257: Reward = -1715.0340026344986\n",
      "Episode 258: Reward = -1791.7457149814497\n",
      "Episode 259: Reward = -1838.1805144668438\n",
      "Episode 260: Reward = -1799.8933035633438\n",
      "Episode 261: Reward = -1848.5053140548644\n",
      "Episode 262: Reward = -1768.9703111805945\n",
      "Episode 263: Reward = -1847.2647045294698\n",
      "Episode 264: Reward = -1534.2511160460137\n",
      "Episode 265: Reward = -1604.9989980818239\n",
      "Episode 266: Reward = -1589.8698557833252\n",
      "Episode 267: Reward = -1741.6190129537483\n",
      "Episode 268: Reward = -1639.1103536970372\n",
      "Episode 269: Reward = -1515.1243514991022\n",
      "Episode 270: Reward = -1851.9398999509547\n",
      "Episode 271: Reward = -1776.1127928930093\n",
      "Episode 272: Reward = -1688.8238346885987\n",
      "Episode 273: Reward = -1744.4837043301984\n",
      "Episode 274: Reward = -1752.3149262323898\n",
      "Episode 275: Reward = -1650.06613660271\n",
      "Episode 276: Reward = -1583.9850958176733\n",
      "Episode 277: Reward = -1453.3014266516518\n",
      "Episode 278: Reward = -1628.9702023453715\n",
      "Episode 279: Reward = -1629.7247862085908\n",
      "Episode 280: Reward = -1582.430969519846\n",
      "Episode 281: Reward = -1534.3020659633685\n",
      "Episode 282: Reward = -1090.2652897862854\n",
      "Episode 283: Reward = -1551.1244621445835\n",
      "Episode 284: Reward = -1505.7358026921452\n",
      "Episode 285: Reward = -1318.9175872128897\n",
      "Episode 286: Reward = -1142.9405981665134\n",
      "Episode 287: Reward = -1479.4325604191229\n",
      "Episode 288: Reward = -1574.70440578035\n",
      "Episode 289: Reward = -1535.0761378840405\n",
      "Episode 290: Reward = -1591.0529953013624\n",
      "Episode 291: Reward = -1519.153267475643\n",
      "Episode 292: Reward = -1584.5504501695962\n",
      "Episode 293: Reward = -1743.4956328287014\n",
      "Episode 294: Reward = -1662.1924327662914\n",
      "Episode 295: Reward = -1588.1092781240116\n",
      "Episode 296: Reward = -1587.8359017042253\n",
      "Episode 297: Reward = -1595.3480585326993\n",
      "Episode 298: Reward = -1487.3541633337884\n",
      "Episode 299: Reward = -1551.9163626836971\n",
      "Episode 300: Reward = -1588.8635365041062\n",
      "Episode 301: Reward = -1577.5859948613859\n",
      "Episode 302: Reward = -1562.7352986225128\n",
      "Episode 303: Reward = -1650.1200217236274\n",
      "Episode 304: Reward = -1449.7495987709353\n",
      "Episode 305: Reward = -1576.774008315946\n",
      "Episode 306: Reward = -1508.8936062255493\n",
      "Episode 307: Reward = -1591.5912573702042\n",
      "Episode 308: Reward = -1047.3837971478172\n",
      "Episode 309: Reward = -1610.1406449165856\n",
      "Episode 310: Reward = -1633.2229629142694\n",
      "Episode 311: Reward = -1664.186136115743\n",
      "Episode 312: Reward = -1569.9697458771009\n"
     ]
    }
   ],
   "source": [
    "for e in range(episodes):\n",
    "    state = env.reset()\n",
    "    total_reward = 0\n",
    "\n",
    "    for time in range(200):\n",
    "        action_idx = agent.act(state)\n",
    "        action = [action_bins[action_idx]]  # env expects an array\n",
    "\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        agent.remember(state, action_idx, reward, next_state, done)\n",
    "        state = next_state\n",
    "        total_reward += reward\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    # ✅ Replay only once per episode (massively faster)\n",
    "    if len(agent.memory) > batch_size:\n",
    "        agent.replay(batch_size)\n",
    "\n",
    "    print(f\"Episode {e+1}: Reward = {total_reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dac0c2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4435f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296b4e36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f72c94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ed5b17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5fa91b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad049bc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
