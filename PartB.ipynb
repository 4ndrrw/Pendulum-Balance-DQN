{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7a98812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym==0.17.3 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (0.17.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from gym==0.17.3) (1.10.1)\n",
      "Requirement already satisfied: numpy>=1.10.4 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from gym==0.17.3) (1.24.3)\n",
      "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from gym==0.17.3) (1.5.0)\n",
      "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from gym==0.17.3) (1.6.0)\n",
      "Requirement already satisfied: future in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from pyglet<=1.5.0,>=1.4.0->gym==0.17.3) (1.0.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (3.7.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from matplotlib) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from matplotlib) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: numpy<2,>=1.20 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from matplotlib) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from matplotlib) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from matplotlib) (6.4.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib) (3.20.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: tensorflow==2.10 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (2.10.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from tensorflow==2.10) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from tensorflow==2.10) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from tensorflow==2.10) (25.2.10)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from tensorflow==2.10) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from tensorflow==2.10) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from tensorflow==2.10) (3.11.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from tensorflow==2.10) (1.1.2)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from tensorflow==2.10) (18.1.1)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from tensorflow==2.10) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from tensorflow==2.10) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from tensorflow==2.10) (24.1)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from tensorflow==2.10) (3.19.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from tensorflow==2.10) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from tensorflow==2.10) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from tensorflow==2.10) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from tensorflow==2.10) (4.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from tensorflow==2.10) (1.17.2)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from tensorflow==2.10) (0.31.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from tensorflow==2.10) (1.70.0)\n",
      "Requirement already satisfied: tensorboard<2.11,>=2.10 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from tensorflow==2.10) (2.10.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from tensorflow==2.10) (2.10.0)\n",
      "Requirement already satisfied: keras<2.11,>=2.10.0 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from tensorflow==2.10) (2.10.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from astunparse>=1.6.0->tensorflow==2.10) (0.44.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10) (2.40.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10) (3.7)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10) (2.32.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10) (3.0.6)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10) (4.9.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow==2.10) (2.0.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow==2.10) (7.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow==2.10) (2.1.3)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow==2.10) (3.20.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10) (0.6.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\65882\\anaconda3\\envs\\rl\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow==2.10) (3.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install gym==0.17.3\n",
    "!pip install matplotlib\n",
    "!pip install tensorflow==2.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5db404f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import gym\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f972e433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.  0.  2.]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "NUM_ACTIONS = 3 \n",
    "action_bins = np.linspace(-2, 2, NUM_ACTIONS) \n",
    "print(action_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6372242d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#the parameters like gamma, epsilon, epsilon_min, epsilon_decay, learning_rate, alpha, etc. are they all correct?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "488494d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=100000)\n",
    "        self.gamma = 0.99           # Discount factor -----------------ASK CHER\n",
    "        self.epsilon = 1.0          # Exploration rate \n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.learning_rate = 0.001\n",
    "\n",
    "        self.model = self._build_model()\n",
    "\n",
    "    def _build_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(12, input_dim=self.state_size, activation='relu'))\n",
    "        model.add(Dense(12, activation='relu'))\n",
    "        model.add(Dense(self.action_size, activation='linear'))  # Q-values for each discrete action\n",
    "        model.compile(loss='mse', optimizer=Adam(learning_rate=self.learning_rate))\n",
    "        return model\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def act(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(self.action_size)\n",
    "        act_values = self.model.predict(state[np.newaxis, :], verbose=0)\n",
    "        return np.argmax(act_values[0])\n",
    "\n",
    "    def replay(self, batch_size):\n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "    \n",
    "        states = np.zeros((batch_size, self.state_size))\n",
    "        targets = np.zeros((batch_size, self.action_size))\n",
    "    \n",
    "        for i, (state, action, reward, next_state, done) in enumerate(minibatch):\n",
    "            target = reward\n",
    "            if not done:\n",
    "                target += self.gamma * np.amax(self.model.predict(next_state[np.newaxis, :], verbose=0)[0])\n",
    "            target_f = self.model.predict(state[np.newaxis, :], verbose=0)[0]\n",
    "            target_f[action] = target\n",
    "    \n",
    "            states[i] = state\n",
    "            targets[i] = target_f\n",
    "    \n",
    "        \n",
    "        self.model.fit(states, targets, epochs=1, verbose=0)\n",
    "    \n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47747c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('Pendulum-v0')  # gym 0.17.3\n",
    "state_size = env.observation_space.shape[0]\n",
    "action_size = NUM_ACTIONS  # number of discrete actions\n",
    "\n",
    "agent = DQNAgent(state_size, action_size)\n",
    "episodes = 100000\n",
    "batch_size = 64\n",
    "\n",
    "max_reward= -5\n",
    "reward_history = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049a8417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: Reward = -998.7016510373827\n",
      "Episode 2: Reward = -1579.2324119851214\n",
      "Episode 3: Reward = -1351.459454464147\n",
      "Episode 4: Reward = -1695.7104671279446\n",
      "Episode 5: Reward = -1340.428114136991\n",
      "Episode 6: Reward = -900.9022290683072\n",
      "Episode 7: Reward = -885.0912354876874\n",
      "Episode 8: Reward = -1172.3869422969674\n",
      "Episode 9: Reward = -944.0884249203689\n",
      "Episode 10: Reward = -988.7033492161648\n",
      "Episode 11: Reward = -1434.2484688468562\n",
      "Episode 12: Reward = -1530.1505526327214\n",
      "Episode 13: Reward = -903.751706995634\n",
      "Episode 14: Reward = -1084.880638089237\n",
      "Episode 15: Reward = -747.3900425651003\n",
      "Episode 16: Reward = -1305.491606355525\n",
      "Episode 17: Reward = -898.365321111625\n",
      "Episode 18: Reward = -909.0033210615195\n",
      "Episode 19: Reward = -1429.857217915887\n",
      "Episode 20: Reward = -1204.7999842257716\n",
      "Episode 21: Reward = -936.2859230806695\n",
      "Episode 22: Reward = -971.1713527952638\n",
      "Episode 23: Reward = -1313.2294477219966\n",
      "Episode 24: Reward = -1425.6190878585542\n",
      "Episode 25: Reward = -1377.5492508650777\n",
      "Episode 26: Reward = -913.1904094233288\n",
      "Episode 27: Reward = -1622.2588560812603\n",
      "Episode 28: Reward = -885.1655667534762\n",
      "Episode 29: Reward = -992.1065776561029\n",
      "Episode 30: Reward = -1064.4558296462556\n",
      "Episode 31: Reward = -792.4584340862493\n",
      "Episode 32: Reward = -766.346110185368\n",
      "Episode 33: Reward = -1500.2324272840012\n",
      "Episode 34: Reward = -1100.2698494321974\n",
      "Episode 35: Reward = -952.761352907087\n",
      "Episode 36: Reward = -1009.8444152550645\n",
      "Episode 37: Reward = -1654.741741294142\n",
      "Episode 38: Reward = -1546.9981873477805\n",
      "Episode 39: Reward = -1485.8421423913228\n",
      "Episode 40: Reward = -1449.2902509216015\n",
      "Episode 41: Reward = -1048.108468524924\n",
      "Episode 42: Reward = -1196.0084186666747\n",
      "Episode 43: Reward = -1273.7472381345392\n",
      "Episode 44: Reward = -822.7788244451385\n",
      "Episode 45: Reward = -1176.6764382752206\n",
      "Episode 46: Reward = -1614.3945098689996\n",
      "Episode 47: Reward = -1701.7771997545867\n",
      "Episode 48: Reward = -1155.6206488495757\n",
      "Episode 49: Reward = -1175.0920337904697\n",
      "Episode 50: Reward = -1234.8583514969064\n",
      "Episode 51: Reward = -1513.7425034262556\n",
      "Episode 52: Reward = -1108.604866270867\n",
      "Episode 53: Reward = -1796.4239390517696\n",
      "Episode 54: Reward = -1175.979521149538\n",
      "Episode 55: Reward = -1620.3710337863542\n",
      "Episode 56: Reward = -1569.496583701463\n",
      "Episode 57: Reward = -1747.5570514765225\n",
      "Episode 58: Reward = -1494.8834673387357\n",
      "Episode 59: Reward = -1744.3107702640082\n",
      "Episode 60: Reward = -1390.4552664231219\n",
      "Episode 61: Reward = -1713.7246591338505\n",
      "Episode 62: Reward = -1144.1108760158656\n",
      "Episode 63: Reward = -1545.1373062945445\n",
      "Episode 64: Reward = -1282.0796017999542\n",
      "Episode 65: Reward = -1052.700673646945\n",
      "Episode 66: Reward = -1211.0428046098757\n",
      "Episode 67: Reward = -1063.1512370007276\n",
      "Episode 68: Reward = -1691.291990408617\n",
      "Episode 69: Reward = -1778.7664432762995\n",
      "Episode 70: Reward = -1735.553516018767\n",
      "Episode 71: Reward = -1645.4890469576062\n",
      "Episode 72: Reward = -1763.4203301099888\n",
      "Episode 73: Reward = -1750.7781302759186\n",
      "Episode 74: Reward = -1413.450136125746\n",
      "Episode 75: Reward = -1767.0361942564966\n",
      "Episode 76: Reward = -1670.0864267532784\n",
      "Episode 77: Reward = -1555.8813808233988\n",
      "Episode 78: Reward = -1580.3638399379033\n",
      "Episode 79: Reward = -1352.832210974057\n",
      "Episode 80: Reward = -1670.659348056111\n",
      "Episode 81: Reward = -1172.0306978312474\n",
      "Episode 82: Reward = -1458.9018864165068\n",
      "Episode 83: Reward = -1789.4168357226001\n",
      "Episode 84: Reward = -1687.483680237555\n",
      "Episode 85: Reward = -1588.6257764760871\n",
      "Episode 86: Reward = -1224.302667858264\n",
      "Episode 87: Reward = -1697.587670925532\n",
      "Episode 88: Reward = -1398.8860324540208\n",
      "Episode 89: Reward = -1462.2357189110164\n",
      "Episode 90: Reward = -1206.1038295734627\n",
      "Episode 91: Reward = -1739.5592587272604\n",
      "Episode 92: Reward = -1487.844128589944\n",
      "Episode 93: Reward = -1204.731952778486\n",
      "Episode 94: Reward = -1348.7278328011644\n",
      "Episode 95: Reward = -1623.5463122716512\n",
      "Episode 96: Reward = -1475.6388123049617\n",
      "Episode 97: Reward = -1659.0935221058032\n",
      "Episode 98: Reward = -1358.9923873799303\n",
      "Episode 99: Reward = -1600.283860917104\n",
      "Episode 100: Reward = -1483.7389245098757\n",
      "Episode 101: Reward = -1171.4490130953955\n",
      "Episode 102: Reward = -1314.4768706413447\n",
      "Episode 103: Reward = -1602.2767962657829\n",
      "Episode 104: Reward = -1718.7396715010502\n",
      "Episode 105: Reward = -1588.3745015740437\n",
      "Episode 106: Reward = -1497.6025454681587\n",
      "Episode 107: Reward = -1486.0424951645696\n",
      "Episode 108: Reward = -1385.7475738992177\n",
      "Episode 109: Reward = -1668.8239371375307\n",
      "Episode 110: Reward = -1071.3253795952226\n",
      "Episode 111: Reward = -1670.7909520579556\n",
      "Episode 112: Reward = -855.8540036866165\n",
      "Episode 113: Reward = -1727.9688302861252\n",
      "Episode 114: Reward = -1515.8367138853146\n",
      "Episode 115: Reward = -1457.5741857298833\n",
      "Episode 116: Reward = -1713.160801395557\n",
      "Episode 117: Reward = -1704.233719621149\n",
      "Episode 118: Reward = -1021.7920073716957\n",
      "Episode 119: Reward = -1652.497114101657\n",
      "Episode 120: Reward = -1499.1295135707599\n",
      "Episode 121: Reward = -1215.2246285697886\n",
      "Episode 122: Reward = -1549.7164845708064\n",
      "Episode 123: Reward = -1717.9759604501048\n",
      "Episode 124: Reward = -1580.6439723998458\n",
      "Episode 125: Reward = -1682.1027293023103\n",
      "Episode 126: Reward = -1701.2929780743716\n",
      "Episode 127: Reward = -1271.6911812262697\n",
      "Episode 128: Reward = -1585.9907292323292\n",
      "Episode 129: Reward = -1380.4508814179515\n",
      "Episode 130: Reward = -1664.978197333787\n",
      "Episode 131: Reward = -1696.3418756054061\n",
      "Episode 132: Reward = -1601.325411536309\n",
      "Episode 133: Reward = -1488.8162314192878\n",
      "Episode 134: Reward = -1502.801499159692\n",
      "Episode 135: Reward = -1348.504348942031\n",
      "Episode 136: Reward = -1639.1518304316692\n",
      "Episode 137: Reward = -1479.4005130428695\n",
      "Episode 138: Reward = -1457.3093378365454\n",
      "Episode 139: Reward = -1466.629789461232\n",
      "Episode 140: Reward = -1656.7568045095913\n",
      "Episode 141: Reward = -1605.4007169105919\n",
      "Episode 142: Reward = -1580.3878504811778\n",
      "Episode 143: Reward = -1134.647469540267\n",
      "Episode 144: Reward = -1030.5525526719468\n",
      "Episode 145: Reward = -1242.1084082710572\n",
      "Episode 146: Reward = -1391.1823466886576\n",
      "Episode 147: Reward = -1273.8609954113258\n",
      "Episode 148: Reward = -1123.2644544288062\n",
      "Episode 149: Reward = -1599.85615388935\n",
      "Episode 150: Reward = -1583.266478512402\n",
      "Episode 151: Reward = -1649.410437413483\n",
      "Episode 152: Reward = -1372.1319368726126\n",
      "Episode 153: Reward = -1264.5225298980843\n",
      "Episode 154: Reward = -1566.9892151848233\n",
      "Episode 155: Reward = -1609.4670007569287\n",
      "Episode 156: Reward = -1561.970304332444\n",
      "Episode 157: Reward = -1641.1238621474279\n",
      "Episode 158: Reward = -1470.4841172281733\n",
      "Episode 159: Reward = -1598.1498201123147\n",
      "Episode 160: Reward = -1327.2037384446598\n",
      "Episode 161: Reward = -1488.1373074356397\n",
      "Episode 162: Reward = -753.8457516540464\n",
      "Episode 163: Reward = -884.2862489009678\n",
      "Episode 164: Reward = -1667.1087518541174\n",
      "Episode 165: Reward = -1491.4805714929344\n",
      "Episode 166: Reward = -1676.8360460751746\n",
      "Episode 167: Reward = -1281.8823695252486\n",
      "Episode 168: Reward = -1373.0549865978926\n",
      "Episode 169: Reward = -1354.566889402387\n",
      "Episode 170: Reward = -1464.0885659357807\n",
      "Episode 171: Reward = -1602.134876916428\n",
      "Episode 172: Reward = -1626.2707451220058\n",
      "Episode 173: Reward = -1584.1272515741648\n",
      "Episode 174: Reward = -1594.281459843004\n",
      "Episode 175: Reward = -1363.2066263204306\n",
      "Episode 176: Reward = -1636.8694309466155\n",
      "Episode 177: Reward = -1369.8794439447627\n",
      "Episode 178: Reward = -1578.506948067869\n",
      "Episode 179: Reward = -1271.142580712242\n",
      "Episode 180: Reward = -1615.7268552404646\n",
      "Episode 181: Reward = -1545.3881425896898\n",
      "Episode 182: Reward = -1582.7851810853524\n",
      "Episode 183: Reward = -1432.144687794519\n",
      "Episode 184: Reward = -1415.6625812385585\n",
      "Episode 185: Reward = -1679.2610744858837\n",
      "Episode 186: Reward = -1565.6229791863868\n",
      "Episode 187: Reward = -1544.6593644026013\n",
      "Episode 188: Reward = -1339.9153643955021\n",
      "Episode 189: Reward = -1408.3866760597168\n",
      "Episode 190: Reward = -1512.637255783758\n",
      "Episode 191: Reward = -1401.839032301129\n",
      "Episode 192: Reward = -1659.1808892420154\n",
      "Episode 193: Reward = -1587.170213064062\n",
      "Episode 194: Reward = -1638.8010374571115\n",
      "Episode 195: Reward = -1641.9917092080261\n",
      "Episode 196: Reward = -1581.8315532461077\n",
      "Episode 197: Reward = -1407.260687787168\n",
      "Episode 198: Reward = -1542.2514010761126\n",
      "Episode 199: Reward = -1480.0035889509152\n",
      "Episode 200: Reward = -1114.4185120668033\n",
      "Episode 201: Reward = -1681.652069515648\n",
      "Episode 202: Reward = -1651.1696272588813\n",
      "Episode 203: Reward = -1380.8979078021853\n",
      "Episode 204: Reward = -1343.6644109993622\n",
      "Episode 205: Reward = -1471.9950555525497\n",
      "Episode 206: Reward = -1372.7665987619434\n",
      "Episode 207: Reward = -1685.714999053635\n",
      "Episode 208: Reward = -1296.747392869044\n",
      "Episode 209: Reward = -1793.65096074114\n",
      "Episode 210: Reward = -1881.33488396865\n",
      "Episode 211: Reward = -1779.0120780447887\n",
      "Episode 212: Reward = -1725.1003580619338\n",
      "Episode 213: Reward = -1398.8981188783953\n",
      "Episode 214: Reward = -1664.8391720242803\n",
      "Episode 215: Reward = -1585.675170057082\n",
      "Episode 216: Reward = -1526.283304537023\n",
      "Episode 217: Reward = -1312.9950601534274\n",
      "Episode 218: Reward = -1449.9978638513956\n",
      "Episode 219: Reward = -1544.1681921642812\n",
      "Episode 220: Reward = -1550.8352754233565\n",
      "Episode 221: Reward = -1479.885774958351\n",
      "Episode 222: Reward = -1459.5875648831875\n",
      "Episode 223: Reward = -1558.729554453198\n",
      "Episode 224: Reward = -1550.0189485706098\n",
      "Episode 225: Reward = -1479.4620632079636\n",
      "Episode 226: Reward = -1475.6086661889549\n",
      "Episode 227: Reward = -1855.3562722291515\n",
      "Episode 228: Reward = -1601.5472675963629\n",
      "Episode 229: Reward = -1238.7585662359315\n",
      "Episode 230: Reward = -1734.266033794421\n",
      "Episode 231: Reward = -1249.7466252591148\n",
      "Episode 232: Reward = -1326.548195719656\n",
      "Episode 233: Reward = -1497.7522151104615\n",
      "Episode 234: Reward = -1797.315645852823\n",
      "Episode 235: Reward = -1785.2276496047173\n",
      "Episode 236: Reward = -1694.0344128637603\n",
      "Episode 237: Reward = -1811.1714417730097\n",
      "Episode 238: Reward = -1533.098496338173\n",
      "Episode 239: Reward = -1433.7710291038027\n",
      "Episode 240: Reward = -1463.9904254105002\n",
      "Episode 241: Reward = -1508.552569894312\n",
      "Episode 242: Reward = -1600.9964679763189\n",
      "Episode 243: Reward = -1521.477652149579\n",
      "Episode 244: Reward = -1433.5816954741392\n",
      "Episode 245: Reward = -1426.504711795206\n",
      "Episode 246: Reward = -1550.0680966618381\n",
      "Episode 247: Reward = -1466.5029555792319\n",
      "Episode 248: Reward = -1618.9536414246231\n",
      "Episode 249: Reward = -1620.959719355476\n",
      "Episode 250: Reward = -1532.4497495967387\n",
      "Episode 251: Reward = -1544.0309401877448\n",
      "Episode 252: Reward = -1580.7882321410762\n",
      "Episode 253: Reward = -1625.720777590935\n",
      "Episode 254: Reward = -1465.4857523424505\n",
      "Episode 255: Reward = -1618.9833090049801\n",
      "Episode 256: Reward = -1529.0759355723544\n",
      "Episode 257: Reward = -1633.3999866983247\n",
      "Episode 258: Reward = -1584.9285600848407\n",
      "Episode 259: Reward = -1683.3435576267632\n",
      "Episode 260: Reward = -1680.610499849304\n",
      "Episode 261: Reward = -1626.1722812468117\n",
      "Episode 262: Reward = -1632.694051595499\n",
      "Episode 263: Reward = -1488.351535847505\n",
      "Episode 264: Reward = -1599.59373365198\n",
      "Episode 265: Reward = -1505.43459679715\n",
      "Episode 266: Reward = -1352.1628510354062\n",
      "Episode 267: Reward = -1346.2178214137436\n",
      "Episode 268: Reward = -1539.0661073978738\n",
      "Episode 269: Reward = -1386.200348475624\n",
      "Episode 270: Reward = -1510.3065011861631\n",
      "Episode 271: Reward = -1403.8358806729066\n",
      "Episode 272: Reward = -1571.3843342817404\n",
      "Episode 273: Reward = -1503.2166265267326\n",
      "Episode 274: Reward = -939.4915948970162\n",
      "Episode 275: Reward = -1622.583998058524\n",
      "Episode 276: Reward = -1509.6184041470958\n",
      "Episode 277: Reward = -1224.0131576215128\n",
      "Episode 278: Reward = -1447.4197046457061\n",
      "Episode 279: Reward = -1506.015244189067\n",
      "Episode 280: Reward = -1374.3586580726185\n",
      "Episode 281: Reward = -1627.2519119244719\n",
      "Episode 282: Reward = -1502.2670956497827\n",
      "Episode 283: Reward = -1639.5815463134102\n",
      "Episode 284: Reward = -1610.487665620216\n",
      "Episode 285: Reward = -1554.4223153778273\n",
      "Episode 286: Reward = -1634.3433560635663\n",
      "Episode 287: Reward = -1558.1621780496814\n",
      "Episode 288: Reward = -1611.5162074872449\n",
      "Episode 289: Reward = -1502.3975695540316\n",
      "Episode 290: Reward = -1606.781513346848\n",
      "Episode 291: Reward = -1414.6969247665982\n",
      "Episode 292: Reward = -1313.2869648051749\n",
      "Episode 293: Reward = -1734.8999089123377\n",
      "Episode 294: Reward = -1526.5247522455966\n",
      "Episode 295: Reward = -1286.8946893705117\n",
      "Episode 296: Reward = -1774.3819375342894\n",
      "Episode 297: Reward = -1050.258249326077\n",
      "Episode 298: Reward = -1829.4000756816533\n",
      "Episode 299: Reward = -1262.8524688459927\n",
      "Episode 300: Reward = -1216.1114465914204\n",
      "Episode 301: Reward = -1416.0263890014357\n",
      "Episode 302: Reward = -1340.9995894212184\n",
      "Episode 303: Reward = -948.9862276059517\n",
      "Episode 304: Reward = -1001.507606358723\n",
      "Episode 305: Reward = -1449.2393775290425\n",
      "Episode 306: Reward = -751.2686218247256\n",
      "Episode 307: Reward = -1571.1438141466601\n",
      "Episode 308: Reward = -880.8279801131762\n",
      "Episode 309: Reward = -1574.0445386422562\n",
      "Episode 310: Reward = -1278.2902483359867\n",
      "Episode 311: Reward = -1666.2613508231314\n",
      "Episode 312: Reward = -1614.0040419890602\n",
      "Episode 313: Reward = -1420.824826085964\n",
      "Episode 314: Reward = -1651.7930063159713\n",
      "Episode 315: Reward = -1745.9879975298993\n",
      "Episode 316: Reward = -1798.218559197025\n",
      "Episode 317: Reward = -1693.2253627007226\n",
      "Episode 318: Reward = -1458.215894380343\n",
      "Episode 319: Reward = -1632.4653451550912\n",
      "Episode 320: Reward = -1668.2553956160384\n",
      "Episode 321: Reward = -1582.6132768515463\n",
      "Episode 322: Reward = -1636.4918820478229\n",
      "Episode 323: Reward = -1618.768323226929\n",
      "Episode 324: Reward = -1724.72873200652\n",
      "Episode 325: Reward = -1771.7787907608374\n",
      "Episode 326: Reward = -1851.465407503701\n",
      "Episode 327: Reward = -1497.98467440916\n",
      "Episode 328: Reward = -1824.6400532893663\n",
      "Episode 329: Reward = -1459.4784294400338\n",
      "Episode 330: Reward = -1569.9933011507758\n",
      "Episode 331: Reward = -1594.6856287069163\n",
      "Episode 332: Reward = -1584.7242494420514\n",
      "Episode 333: Reward = -1363.5334038099106\n",
      "Episode 334: Reward = -1516.1287443279223\n",
      "Episode 335: Reward = -1407.5558854043552\n",
      "Episode 336: Reward = -385.5023940634266\n",
      "Episode 337: Reward = -1436.855225610766\n",
      "Episode 338: Reward = -6.276274678413548\n",
      "Episode 339: Reward = -1613.1898091997052\n",
      "Episode 340: Reward = -3.351265989103136\n",
      "Episode 341: Reward = -1595.8389488894782\n",
      "Episode 342: Reward = -1316.6030156852532\n",
      "Episode 343: Reward = -1297.1438982045581\n",
      "Episode 344: Reward = -1354.4287992568618\n",
      "Episode 345: Reward = -1487.7349647678511\n",
      "Episode 346: Reward = -1608.5975172500364\n",
      "Episode 347: Reward = -1586.5805552308232\n",
      "Episode 348: Reward = -1507.0330746560983\n",
      "Episode 349: Reward = -1523.3846212644924\n",
      "Episode 350: Reward = -1571.5881369534086\n",
      "Episode 351: Reward = -1564.7267339921643\n",
      "Episode 352: Reward = -1595.6903255413865\n",
      "Episode 353: Reward = -1579.4314200234521\n",
      "Episode 354: Reward = -1534.3387906929463\n",
      "Episode 355: Reward = -1788.1111394224567\n",
      "Episode 356: Reward = -1661.3676986307926\n",
      "Episode 357: Reward = -1543.3436606454966\n",
      "Episode 358: Reward = -1501.990654505391\n",
      "Episode 359: Reward = -1629.3873129265576\n",
      "Episode 360: Reward = -1582.4969970474904\n",
      "Episode 361: Reward = -1592.332594778667\n",
      "Episode 362: Reward = -1495.345190504516\n",
      "Episode 363: Reward = -1472.5338196337548\n",
      "Episode 364: Reward = -1181.8014251010363\n",
      "Episode 365: Reward = -1347.6329436307528\n",
      "Episode 366: Reward = -1315.923419896694\n",
      "Episode 367: Reward = -1519.986411556581\n",
      "Episode 368: Reward = -1555.9542916708454\n",
      "Episode 369: Reward = -1332.6795802344702\n",
      "Episode 370: Reward = -1593.7475276578662\n",
      "Episode 371: Reward = -1248.9584506741362\n",
      "Episode 372: Reward = -1346.5619726346579\n",
      "Episode 373: Reward = -1572.5582242352123\n",
      "Episode 374: Reward = -1536.9127413421256\n",
      "Episode 375: Reward = -1241.5546098499963\n",
      "Episode 376: Reward = -1169.403871006712\n",
      "Episode 377: Reward = -1487.7956714478933\n",
      "Episode 378: Reward = -1268.92687545327\n",
      "Episode 379: Reward = -1516.028665390159\n",
      "Episode 380: Reward = -1391.3121175061567\n",
      "Episode 381: Reward = -1504.915288653798\n",
      "Episode 382: Reward = -1457.0226260322631\n",
      "Episode 383: Reward = -1308.2154596188727\n",
      "Episode 384: Reward = -1508.1520042285122\n",
      "Episode 385: Reward = -1465.9322565816597\n",
      "Episode 386: Reward = -1487.319739982472\n",
      "Episode 387: Reward = -1167.7966339642458\n",
      "Episode 388: Reward = -1522.3035197048673\n",
      "Episode 389: Reward = -1307.034694720777\n",
      "Episode 390: Reward = -1548.2971541512811\n",
      "Episode 391: Reward = -1318.7565508035482\n",
      "Episode 392: Reward = -1554.51807478272\n",
      "Episode 393: Reward = -1603.4176780341754\n",
      "Episode 394: Reward = -1531.0797152356524\n",
      "Episode 395: Reward = -1171.0386050997365\n",
      "Episode 396: Reward = -1529.6840680292082\n",
      "Episode 397: Reward = -1506.7472588088576\n",
      "Episode 398: Reward = -1068.8233485997978\n",
      "Episode 399: Reward = -1857.4795868855917\n",
      "Episode 400: Reward = -1829.9914629460282\n",
      "Episode 401: Reward = -1783.1325484377876\n",
      "Episode 402: Reward = -1613.849042928541\n",
      "Episode 403: Reward = -1581.195223140732\n",
      "Episode 404: Reward = -1583.1544259713294\n",
      "Episode 405: Reward = -5.053082267345234\n",
      "Episode 406: Reward = -1286.4502118650878\n",
      "Episode 407: Reward = -3.9110899663693672\n",
      "Episode 408: Reward = -1619.1812278427417\n",
      "Episode 409: Reward = -1611.1356463992242\n",
      "Episode 410: Reward = -1554.8889277498188\n",
      "Episode 411: Reward = -1539.7643561415834\n",
      "Episode 412: Reward = -1596.6780974448325\n",
      "Episode 413: Reward = -1537.7416556457752\n",
      "Episode 414: Reward = -761.2718438877054\n",
      "Episode 415: Reward = -1356.3528045384423\n",
      "Episode 416: Reward = -1463.6893219713804\n",
      "Episode 417: Reward = -761.8753026972395\n",
      "Episode 418: Reward = -1410.352049063689\n",
      "Episode 419: Reward = -1539.6055282065506\n",
      "Episode 420: Reward = -1564.5828965055534\n",
      "Episode 421: Reward = -1604.7286626613954\n",
      "Episode 422: Reward = -3.0101548658993798\n",
      "Episode 423: Reward = -1626.8843653515726\n",
      "Episode 424: Reward = -1771.4280731381007\n",
      "Episode 425: Reward = -1521.6533943532029\n",
      "Episode 426: Reward = -1654.3867579130501\n",
      "Episode 427: Reward = -1675.1954602273963\n",
      "Episode 428: Reward = -1550.7067082006479\n",
      "Episode 429: Reward = -1073.5745010952426\n",
      "Episode 430: Reward = -1065.3521729045444\n",
      "Episode 431: Reward = -1672.7409152376538\n",
      "Episode 432: Reward = -1303.1946025569769\n",
      "Episode 433: Reward = -1711.9329325460683\n",
      "Episode 434: Reward = -1482.386218203286\n",
      "Episode 435: Reward = -1307.8306193693968\n",
      "Episode 436: Reward = -1720.9379406186442\n",
      "Episode 437: Reward = -1496.3057995837707\n",
      "Episode 438: Reward = -1298.2322381135057\n",
      "Episode 439: Reward = -1694.514923908686\n",
      "Episode 440: Reward = -1517.1922560570176\n",
      "Episode 441: Reward = -1465.1549238450655\n",
      "Episode 442: Reward = -1013.6683096375687\n",
      "Episode 443: Reward = -1478.0013681160287\n",
      "Episode 444: Reward = -1291.6725293982297\n",
      "Episode 445: Reward = -1840.0415409238283\n",
      "Episode 446: Reward = -1429.5249889054905\n",
      "Episode 447: Reward = -1604.7949664235641\n",
      "Episode 448: Reward = -1225.4397261605084\n",
      "Episode 449: Reward = -1296.7663473807306\n",
      "Episode 450: Reward = -1403.431380376416\n",
      "Episode 451: Reward = -930.3223981268156\n",
      "Episode 452: Reward = -1888.8080750308172\n",
      "Episode 453: Reward = -1313.4982184785101\n",
      "Episode 454: Reward = -1526.6185615721556\n",
      "Episode 455: Reward = -1831.3196725111784\n",
      "Episode 456: Reward = -1477.5100170935964\n",
      "Episode 457: Reward = -1552.4965066229888\n",
      "Episode 458: Reward = -1583.402291669557\n",
      "Episode 459: Reward = -1561.728367876867\n",
      "Episode 460: Reward = -1187.2167739422364\n",
      "Episode 461: Reward = -987.1246273302907\n",
      "Episode 462: Reward = -1320.5851784023616\n",
      "Episode 463: Reward = -1440.4093115348567\n",
      "Episode 464: Reward = -869.2224774757441\n",
      "Episode 465: Reward = -1602.7826824076155\n",
      "Episode 466: Reward = -639.3702503694332\n",
      "Episode 467: Reward = -1641.935991914823\n",
      "Episode 468: Reward = -1200.9668735298235\n",
      "Episode 469: Reward = -1033.0049045557694\n",
      "Episode 470: Reward = -871.5201977153664\n",
      "Episode 471: Reward = -645.6362822869962\n",
      "Episode 472: Reward = -1619.138684501661\n",
      "Episode 473: Reward = -1239.4003573644736\n",
      "Episode 474: Reward = -1070.9820213572702\n",
      "Episode 475: Reward = -1533.7111931360848\n",
      "Episode 476: Reward = -1243.744508293919\n",
      "Episode 477: Reward = -985.3245666889213\n",
      "Episode 478: Reward = -1315.7316795318566\n",
      "Episode 479: Reward = -1572.30921543344\n",
      "Episode 480: Reward = -1523.0384972826955\n",
      "Episode 481: Reward = -1198.4837760295884\n",
      "Episode 482: Reward = -1537.892991134571\n",
      "Episode 483: Reward = -1179.7706713817847\n",
      "Episode 484: Reward = -1500.9296073819091\n",
      "Episode 485: Reward = -1309.8613607476893\n",
      "Episode 486: Reward = -945.9773285370283\n",
      "Episode 487: Reward = -1516.0855595661017\n",
      "Episode 488: Reward = -1588.0176065721812\n",
      "Episode 489: Reward = -1183.837815952129\n",
      "Episode 490: Reward = -1084.5635796085712\n",
      "Episode 491: Reward = -1586.6242581679335\n",
      "Episode 492: Reward = -1600.7961763706126\n",
      "Episode 493: Reward = -1356.26558219582\n",
      "Episode 494: Reward = -1595.795648485021\n",
      "Episode 495: Reward = -1508.3003707713947\n",
      "Episode 496: Reward = -1516.6646264108533\n",
      "Episode 497: Reward = -1432.5094126051802\n",
      "Episode 498: Reward = -1505.5419269163515\n",
      "Episode 499: Reward = -1545.2496394494967\n",
      "Episode 500: Reward = -1484.5718678029739\n"
     ]
    }
   ],
   "source": [
    "for e in range(episodes):\n",
    "    state = env.reset()\n",
    "    total_reward = 0\n",
    "\n",
    "    for time in range(200):\n",
    "        action_idx = agent.act(state)\n",
    "        action = [action_bins[action_idx]]  # env expects an array\n",
    "\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        agent.remember(state, action_idx, reward, next_state, done)\n",
    "        state = next_state\n",
    "        total_reward += reward\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    # ✅ Replay only once per episode (massively faster)\n",
    "    if len(agent.memory) > batch_size:\n",
    "        agent.replay(batch_size)\n",
    "\n",
    "    print(f\"Episode {e+1}: Reward = {total_reward}\")\n",
    "    reward_history.append(total_reward)\n",
    "\n",
    "    if total_reward >= max_reward: \n",
    "        print(f\"✅ Solved! Pendulum upright and still in episode {e+1} with reward {total_reward}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dac0c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#do i need to plot the learnign rate and epsilon cos lioterally define how much its decaying per episode "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4435f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(reward_history, label='Episode Reward')\n",
    "plt.axhline(y=-5, color='r', linestyle='--', label='Target Reward (-5)')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total Reward')\n",
    "plt.title('Pendulum DQN - Reward per Episode')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296b4e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(data, window=10):\n",
    "    return np.convolve(data, np.ones(window)/window, mode='valid')\n",
    "\n",
    "plt.plot(moving_average(reward_history), label='Moving Avg (10 episodes)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f72c94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ed5b17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5fa91b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad049bc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
